{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c042ddbb-c2c9-46ed-b36c-c965c0d7ff5b",
   "metadata": {},
   "source": [
    "# Ask the docs anything about SuperDuperDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858da67-597d-4d98-ae4a-41003bb569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install superduperdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcdade-f988-4464-bfcf-806245031bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42c42cc-af6a-4712-a993-d9c921693819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Vector database URI is the same as the data backend URI. Using the data backend as the vector database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from superduperdb import superduper\n",
    "from superduperdb.db.mongodb.query import Collection\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017\"\n",
    "# mongodb_uri = \"mongodb://superduper:superduper@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from superduperdb import superduper\n",
    "db = superduper(mongodb_uri)\n",
    "\n",
    "collection = Collection('questiondocs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72a2a52-964f-456e-88b6-040965f5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "STRIDE = 5       # stride in numbers of lines\n",
    "WINDOW = 10       # length of window in numbers of lines\n",
    "\n",
    "content = sum([open(file).readlines() for file in glob.glob('../*/*.md') + glob.glob('../*.md')], [])\n",
    "chunks = ['\\n'.join(content[i: i + WINDOW]) for i in range(0, len(content), STRIDE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a3a6ef-6cba-4655-9822-0ea4f9151f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "backend\n",
       "\n",
       "├── ai  # RAG app-specific code\n",
       "\n",
       "│   ├── ...\n",
       "\n",
       "├── documents  # routes for our app\n",
       "\n",
       "│   ├── __init__.py\n",
       "\n",
       "│   ├── models.py  # pydantic models\n",
       "\n",
       "│   └── routes.py  # AI-enhanced CRUD logic\n",
       "\n",
       "├── __init__.py\n",
       "\n",
       "├── app.py  # events that occur at app startup/shutdown\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7208ef2-c035-43b9-a624-ade42a06ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:found 0 uris\n",
      "INFO:root:Adding model text-embedding-ada-002 to db\n",
      "WARNING:root:model/text-embedding-ada-002/1 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "INFO:root:Adding model text-embedding-ada-002 to db\n",
      "WARNING:root:model/text-embedding-ada-002/1 already exists - doing nothing\n",
      "INFO:root:Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing chunk 0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pymongo.results.InsertManyResult at 0x157063fa0>,\n",
       " TaskWorkflow(database=<superduperdb.db.base.db.DB object at 0x156aaa150>, G=<networkx.classes.digraph.DiGraph object at 0x15740a710>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.document import Document\n",
    "\n",
    "db.execute(collection.insert_many([Document({'txt': chunk}) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083ccfdd-0ac1-4749-8c74-857d43eeba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document({'_id': ObjectId('652459fb412eff4a8f12f259'), 'txt': \"# Building a RAG application with FastAPI, MongoDB and SuperDuperDB\\n\\n\\n\\nIn this use-case, we'll use FastAPI to serve SuperDuperDB on [fly.io](https://fly.io/) using MongoDB as a databackend.\\n\\nThe task we'll be implementing is a retrieval augmented text-generation (RAG) app for answering\\n\\nquestions about a particular trove of documents. Read more [on our blog](/blog/...).\\n\\n\\n\\n## Create the FastAPI app file structure\\n\\n\\n\\nThere are many choices here. Please refer to the FastAPI [documentation](https://fastapi.tiangolo.com/tutorial/bigger-applications/) for other possible choices. The structure that we chose looks like the following:\\n\\n\\n\", '_fold': 'train'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(collection.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa132d0-e6a2-46f6-9eb8-13fbce90ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Adding model text-embedding-ada-002 to db\n",
      "WARNING:root:model/text-embedding-ada-002/2 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "443it [00:00, 739.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.vector_index import VectorIndex\n",
    "from superduperdb.container.listener import Listener\n",
    "from superduperdb.ext.openai.model import OpenAIEmbedding\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier='my-index',\n",
    "        indexing_listener=Listener(\n",
    "            model=OpenAIEmbedding(model='text-embedding-ada-002'),\n",
    "            key='txt',\n",
    "            select=collection.find(),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfa4df6-73ac-4d46-8047-011648e24958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-3.5-turbo', 'splitter', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "from superduperdb.ext.openai.model import OpenAIChatCompletion\n",
    "\n",
    "chat = OpenAIChatCompletion(\n",
    "    model='gpt-3.5-turbo',\n",
    "    prompt=(\n",
    "        'Use the following description and code-snippets aboout SuperDuperDB to answer this question about SuperDuperDB\\n'\n",
    "        'Do not use any other information you might have learned about other python packages\\n'\n",
    "        'Only base your answer on the code-snippets retrieved\\n'\n",
    "        '{context}\\n\\n'\n",
    "        'Here\\'s the question:\\n'\n",
    "    ),\n",
    ")\n",
    "\n",
    "db.add(chat)\n",
    "\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cde11c-6c7e-457d-8031-873acaca600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.show('model', 'gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4a0f6c-9e24-47aa-bc73-7cc4507e94ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here's a code-snippet to set up a `VectorIndex` in SuperDuperDB:\n",
       "\n",
       "```python\n",
       "from superduperdb.container.vector_index import VectorIndex\n",
       "from superduperdb.container.listener import Listener\n",
       "\n",
       "# Define the VectorIndex\n",
       "vector_index = VectorIndex(\n",
       "    identifier='my-index',\n",
       "    indexing_listener=Listener(\n",
       "        model=OpenAIEmbedding(model='text-embedding-ada-002'),\n",
       "        key='txt',\n",
       "        select=collection.find(),\n",
       "    ),\n",
       ")\n",
       "\n",
       "# Add the VectorIndex to the database\n",
       "db.add(vector_index)\n",
       "```\n",
       "\n",
       "This code creates a `VectorIndex` object named 'my-index' and sets up a listener using the model 'text-embedding-ada-002' from OpenAI. The 'txt' key is used to extract text data from the collection during indexing. Finally, the `VectorIndex` is added to the SuperDuperDB database using the `db.add()` method."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.container.document import Document\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "q = 'Can you give me a code-snippet to set up a `VectorIndex`?'\n",
    "\n",
    "output, context = db.predict(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    input=q,\n",
    "    context_select=(\n",
    "        collection\n",
    "            .like(Document({'txt': q}), vector_index='my-index', n=5)\n",
    "            .find()\n",
    "    ),\n",
    "    context_key='txt',\n",
    ")\n",
    "\n",
    "Markdown(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
